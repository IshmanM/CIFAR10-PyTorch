{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @author: Ishman Mann\n",
    "# @date: 13/10/2022\n",
    "# \n",
    "# @description:\n",
    "#   Classification model for CIFAR-10 dataset using a CNN in pyTorch\n",
    "#\n",
    "# @resources:\n",
    "#\n",
    "#\n",
    "# @notes:\n",
    "#   Only push to 'ishman-pytorch' branch!!\n",
    "#   Use conda env instead of a virtualenv file \n",
    "#\n",
    "# @todo:\n",
    "#   Build model\n",
    "#   Train model -- think of where to put softmax, crossEntropyLoss has softmax in it, so I can't \n",
    "#                  put softmax in my model layers. When computing accuracy, just call softmax there \n",
    "#   Evaluate model, use torchmetrics\n",
    "#   Create a confusion matrix\n",
    "#   Add image augmentation\n",
    "#   Add model saving\n",
    "#   Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Imports\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Documents\\\\computer-vision-bootcamp-pyTorch'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device as gpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete and recreate datasets folder (For Google Colab only)\n",
    "if os.path.exists(\"./datasets\"):\n",
    "  shutil.rmtree(\"./datasets\", ignore_errors=True)\n",
    "  os.makedirs(\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Loading testing and training data\n",
    "\n",
    "trainData = datasets.CIFAR10(\n",
    "    root=\"./datasets\",\n",
    "    train=True, # get train data\n",
    "    download=True,\n",
    "    transform=ToTensor(), # converts PIL to torch.tensor\n",
    "    target_transform=None #dont transform targets (labels)!\n",
    ")\n",
    "\n",
    "testData = datasets.CIFAR10(\n",
    "    root=\"./datasets\",\n",
    "    train=False, # get test data\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None #dont transform targets (labels)!\n",
    ") \n",
    "\n",
    "CLASS_NAMES = trainData.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off some validation data\n",
    "TRAIN_LENGTH = int(len(trainData.data)*0.8)\n",
    "VALIDATE_LENGTH = int(len(trainData.data)*0.2)\n",
    "trainData, validateData = torch.utils.data.random_split(trainData, [TRAIN_LENGTH, VALIDATE_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing a sample image\n",
    "image, label = trainData[0]\n",
    "imagePermuted = image.permute(1,2,0)\n",
    "print(imagePermuted.shape)\n",
    "plt.imshow(imagePermuted)\n",
    "plt.title(CLASS_NAMES[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the data using DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "trainDataloader = DataLoader(trainData, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validateDataloader = DataLoader(validateData, batch_size=BATCH_SIZE, shuffle=False)\n",
    "testDataloader = DataLoader(testData, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# Create the model\n",
    "\n",
    "class CIFAR10ModelV1(nn.Module):\n",
    "\n",
    "  def __init__(self, inputChannels: int, hiddenUnits: int, outputShape: int):\n",
    "    super().__init__()\n",
    "\n",
    "    # Convolution & pooling layers\n",
    "    self.cnn_layer_1 = nn.sequential(\n",
    "      nn.Conv2d(in_channels=inputChannels, out_channels=hiddenUnits,\n",
    "                kernel_size=3, stride=1, padding=\"same\"),\n",
    "      nn.Relu(),\n",
    "      nn.BatchNorm2d(num_features=hiddenUnits, eps=1e-05, momentum=0.1, affine=True),\n",
    "      nn.Conv2d(in_channels=hiddenUnits, out_channels=hiddenUnits,\n",
    "                kernel_size=3, stride=1, padding=\"same\"),\n",
    "      nn.Relu(),\n",
    "      nn.BatchNorm2d(num_features=hiddenUnits, eps=1e-05, momentum=0.1, affine=True),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    self.cnn_layer_2 = nn.sequential(\n",
    "      nn.Conv2d(in_channels=hiddenUnits, out_channels=2*hiddenUnits,\n",
    "                kernel_size=3, stride=1, padding=\"same\"),\n",
    "      nn.Relu(),\n",
    "      nn.BatchNorm2d(num_features=2*hiddenUnits, eps=1e-05, momentum=0.1, affine=True),\n",
    "      nn.Conv2d(in_channels=2*hiddenUnits, out_channels=2*hiddenUnits,\n",
    "                kernel_size=3, stride=1, padding=\"same\"),\n",
    "      nn.Relu(),\n",
    "      nn.BatchNorm2d(num_features=2*hiddenUnits, eps=1e-05, momentum=0.1, affine=True),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "\n",
    "    # Fully connected layers\n",
    "    self.classifier = nn.sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=2*hiddenUnits*8*8, # 8*8 comes from maxpooling 32*32 pixels twice\n",
    "                   out_features=outputShape)\n",
    "    )\n",
    "\n",
    "    # Placing model layers in forward()\n",
    "    def forward(self, x: torch.Tensor):\n",
    "      x = self.cnn_layer_1(x)\n",
    "      x = self.cnn_layer_2(x)\n",
    "      x = self.classifier(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5f1159cfdad2c5db23875de314fc7465df08c3bdb8a1cc0f893debc28ccbaff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
